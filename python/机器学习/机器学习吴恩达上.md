# **吴恩达机器学习系列课程(上)**



## 1

##### Machine Learning

- Grew out of work in AI
- New capability for computers

##### Examples:

- Database mining
- Applications can not program by hand
- Self-customizing programs
- Understanding human learning



##### Machine Learning definition

- Arthur Samuel(1959).Machine Learning:Field of study that gives computers the ability to learn without being explicitly programmed.
- Tom Mitchell(1998)Well-posed Learning Problem:A computer Program is said to learn from experience E with respect to some task T and some performance measure P,if its performance on T,as measured by P,improves with experirence E.



##### Machine learning algorithms:

- Supervised learning (给出数据的具体体现)
- Unsupervised learning（只有数据自行分析）



regression problem

classification problem



clustering algorithm



##### Octave(or matlab)

```octave
[W,s,v]=svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x')
```



## 2

### regression

Notation:

m=Number of training examples

x’s=“input”variable/features

y’s=“output”variable/“target”variable



training set—>learning algorithm—>hypothesis



#### linear regression

hypothesis,parameters,cost function,goal

##### cost function(J)  方差最小函数

##### contour figure  等高线图



#### Gradient descent  algorithm

Have some function J($a_0$,$a_1$)

Want $min_{a_0,a_1}$ J($a_0$,$a_1$​)

##### “Batch” Gradient Descent

“Batch”:Each step of gradient descent uses all the training examples.



沿着最高点依次找到梯度下降的位置。

代价函数可以指函数和点之间距离的方差，可以用普通图像或者等高线图表示，以此寻求最小值。



## 3

##### Matrix: 

Rectangular array of number:

Dimension of matrix: number of rows * number of columns

$A_{ij}$= “i,j entry” in the $i^{th}$ row,$j^{th}$ column



##### Vector:

An n * 1 matrix

$y_i$ = $i^{th}$​ element



##### Matrix Addition 

##### Scalar Multiplication

##### Combination of Operands



##### matrix multiplication

##### inverse and transpose

(linear algebra?)



## 4

### Multiple features(variables)

##### Notation:

n = number of features

$x^{(i)}$ = input (features) of $i^{th}$ training example

$x_j^{(i)}$ = value of feature j in $i^{th}$ training example

(i指训练集索引，j指该训练集中第j个特征值)



##### Hypothesis:

precious: $h_a(x)=a_0+a_1x$

now: $h_a(x)=a_0+a_1x_1+a_2x_2+...+a_nx_n=a^Tx$

($x_0^{(i)}=1$)

##### Parameters: a

##### Cost function: $J(a)=\frac{1}{2m}\sum_{i=1}^m(h_a{(x^{(i)})-y^{(i)}})^2$

##### Gradient descent:

Repeat { $a_j := a_j-\alpha\frac{\partial}{\partial a_j}J(a)$  (simultaneously update for every j=0,…,n) ($x_j^{(i)}$​​)

经过多次梯度下降达到找到最小值的目的



##### feature scaling

##### Mean normalization

(多元梯度下降法)



### Gradient descent:

$\theta_j := \theta_j-\alpha\frac{\partial}{\partial \theta_j}J(\theta)$​  

- how to choose learning rate $\alpha$​
- make sure gradient descent is working correctly

Summary:

- if $\alpha$ is too small: slow convergence.慢
- if $\alpha $ is too large: J($\theta$) may not decrease on every iteration;may not converge.过于快反而慢

[机器学习 —— 多元梯度下降 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/110788042)



#### Linear Regression with multiple variables

##### Features and polynomial regression

选择多种不同的拟合曲线，理解题目本身带有的实际意义

##### Normal equation

Method to solve for $\alpha $ analytically

[详解正规方程（Normal Equation） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/60719445)

$\theta =(X^TX)^{-1}X^TY$



##### compare Gradient Descent and Normal Equation

Gradient Descent

- Need to choose $\alpha $
- Needs many iterations
- Works well even when n is large

归一化，找出合适的从上到下的学习率

Normal Equation

- No need choose $\alpha $
- Don’t need to iterate
- Need to compute $(X^TX)^{-1}$
- Slow if n is very large

利用数学知识求出$\theta $​的值



注：

正规方程在矩阵不可逆情况下的解决办法

- Rudundant feaures(linearly dependent).

- Too many features(m$\le$n).

  Delete som features,or use regularization.



## 5

学会octave/matlab的基本语法，略。

[会用MATLAB的话，还用学Octave吗？区别是什么？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/141128838)



## 6

### Classification

binary class/muti-class problem



Classification: y= 1 or 0(不建议使用线性回归)

$h_\theta(x)$ can be>1 or <0

Logistic Regression:  $0\leq h_\theta(x)\leq1$



#### Logistic Regression

##### Hypothesis Representation

Logistic Regression Model want  $0\leq h_\theta(x)\leq1$

$h_\theta=g(\theta^Tx),g(x)=\frac{1}{1+e^{-x}}(sigmoid/logistic function)$

(sigmod可以将数值转换到0到1中也就类似于概率，需要确立$\theta$对起进行确立以确保符合现实)

##### Decision boundary

$\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2...$

linear decison boundaries

non-linear decision buondaries  

##### Cost function

Training set: {$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})$}

m examples: $x\in\left|\begin {array}{c}x_0 \\x_1\\...\\x_n\end{array}\right| $, $x_0=1,y\in\{0,1\}$

$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$

how to choose parameters $ \theta$?

 

##### ~~linear regression~~:

$Cost(h_\theta(x),y)=\frac{1}{2}(h_\theta(x)-y)^2,J(x)=\frac{1}{m}Cost$​

—>”non-convex function”难以使用梯度下降法求解

##### Logistic regression cost function:

$$Cost(h_\theta(x),y) = \begin{cases}
-log(h_\theta(x)), & \text{if } y=1 \\
-log(1-h_\theta(x)), & \text{if } y=0
\end{cases}$$

—>$Cost(h_\theta(x),y)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))$



##### Simplified cost function and gradient descent

带入J($ \theta$)然后套用梯度下降法的模板得到$ \theta$

 Repeat $\theta_j:=\theta_j-\alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$(simultaneously update all $\theta_j$)



##### Advanced optimization

######  Otimization algorithm

Given $ \theta$ , we have code that can compute J($ \theta,\frac{\partial}{\partial\theta_j}J(\theta)$),(for j=0,1,…,n)

###### Optimization algorithms:

- Gradient descent
- Conjugate gradient
- BFGS
- L-BfGS

advantages:

- No need to manually pich $ \alpha$
- Often faster than gradient descent

disadvantages:

- More complex 



##### Multi-class classification: One-vs-all

Train a lofgistic regression classifier $h_\theta^{(i)}$ for each class i to predict the probability that y=i

On a new input x, to make a prediction,pick the class i that maximizes $max_ih_\theta^{(i)}(x)$



## 7

### Regularization

##### overfitting problem

###### Linear/Logistic regression(housing prices) Overfitting:

if we have too many features,the learned hypothesis may fit the training set very well, but fail to geralize to new examples(predict prices on new example).

###### 

##### Addressing overfitting:

Options:

1.  Reduce number of features.
   - Manually select which features to keep.
   - Model selection algorithm(later in course).
2.  Regularization
   - Keep all the features,but reduce magnitude/values of parameters $ \theta_j$
   - Works well when we have a lot of features,each of which contributes a bit to predicting y.



##### Regularization

Small values for parameters $\theta_0,\theta_1,...,\theta_n$

- “Simmpler” hypothesis
- Less prone to overfitting

Housing

- Features: $x_1,x_2,...,x_{100}$
- Parameters: $\theta_0,\theta_1,...,\theta_{100}$​

In regularized linear regression,we choose $ \theta$ to minimize $J(\theta)=\frac{1}{2m}[\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda_j\sum_{j=1}^n\theta_j^2]$

$\lambda$​–>正则化参数.

What if $ \lambda$ is to set to an extremely large value (perhaps for too large our problem,say $ \lambda=10^{10}$)?

the high regularization.



##### Regularized linear regression

######  Gradient Descent:

$\theta_j:=\theta_j(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$

###### non-invertibility(optional/advanced).

Suppose m$\leq$n,(#examples) (#features)

$\theta=(X^TX)^{-1}X^Ty$

if $\lambda>0$,  $\theta=(X^TX+\lambda[]^{-1})X^Ty$



##### Regularized logistic regression



## 8 

#### Neural Networks Representation

##### Non-linear hypotheses

having machines that can mimic the brain.

##### Neurons and the brain

Origins: Algorithms that try to mimic the brain

Was very widely used in 80s and early 90s; popularity diminished in late 90s.

Recent resuigence: State-of-the-art techine for many applications.



##### Model Representation 

neuron in the brain

neuron model: Logistic unit

$a_i^{(j)}=$ “activation” of unit i in layer j

$\theta^{(j)}=$ matrix of weights controlling function mapping from layer j to layer J+1

$a_1^{(2)}=g(\theta_{10}^{(1)}x_0+\theta_{11}^{(1)}x_1+\theta_{12}^{(1)}x_2+\theta_{13}^{(1)}x_3)$

$h_\theta(x)=a_1^{(3)}=g(\theta_{10}^{(2)}a_0^{(2)}+\theta_{11}^{(2)}a_1^{(2)}+\theta_{12}^{(2)}a_2^{(2)}+\theta_{13}^{(2)}a_3^{(2)})$

if network has $s_j$ units in layer j, $s_{j+1}$ units in layer j+1,then $\theta^{(j)}$ will be of dimension $s_{j+1}*(s_j+1)$



##### Examples and intuitions

8-5 AND  OR  XOR

8-6 NOT  XNOR 多层



#####   Multi classification

multiple output units: One-vs-all 



## 9

#### Neural Networks:Learning

##### Neural Network (Classification)

$\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...(x^{(m)},y^{(m)})\}$

L = total no. of layers in network

$s_l$ = no. of units (not counting bias unit) in layer l

<u>Binary classification</u>

1 output print

<u>Multi-class classification(k classes)</u>

k output units



##### cost function

Logistic regression:

$J(\theta)=-\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$

Neural network:

不对偏差项进行正则化 

$h_\theta(x)\in R^k$     $(h_\theta(x))_i=i^{th} output$



##### Backpropagation algorithm

###### Gradient computation

$J(\theta)=...$   $min_\theta J(\theta)$​

Need code to compute:

- $J(\theta)$
- $\frac{\partial}{\partial\theta_{ij}^{(l)}}J(\theta)$​



Given one training example(x,y):

Forward propagation:

$a^{(1)}=x$

$z^{(2)}=\theta^{(1)}a^{(1)}$

$a^{(2)}=g(z^{(2)})(add a_0^{(2)})$​

if end $a^{(2)}=h_\theta(x)=g(z^{(2)})$

 

Intution: $\delta_j^{(l)}=$ “error” of node j in layer l.

For each output unit (layer L=4)

$\delta_j^{(4)}=a_j^{(4)}-y_j$

$\delta^{(3)}=(\theta^{(3)})^T\delta^{(4)}.*g'(z^{(3)})$

$\delta^{(2)}=(\theta^{(2)})^T\delta^{(3)}.*g'(z^{(2)})$



Training set {$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})$}

Set $\Delta_{ij}^{(l)=0}$ (for all l,i,j)

For i=1 to m

​      Set $a^{(1)}=x^{(i)}$

​      Perform forward propagation to compute $a^{(l)}$ for l=2,3,…L

​      Using $y^{(i)}$,compute $\delta^{(L)}=a^{(L)}-y^{(i)}$

​      Compute $\delta^{(L-1)},\delta^{(L-2)},...,\delta^{(2)}$

​      $\Delta_{ij}^{(l)}:=\Delta_{ij}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$

$D_{ij}^{(l)}:=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\theta_{ij}^{(l)}$  if j$\not=$0

$D_{ij}^{(l)}:=\frac{1}{m}\Delta_{ij}^{(l)}$     if j=0



###### Backpropagation intuition

###### Implementation note: Unrolling parameters

矩阵组合变向量再拆成矩阵.[]，reshape



###### Gradient checking

Implementation Note:

- Implement backprop to compute DVec(unrolled $D^{(1)},D^{(2)},D^{(3)}$)
- Implement numerical gradent check to compute gradApprox
- Make sure they give similiar vulues
- Turn off gradient checking. Using backprop code for learning.

Important:

- Be sure to disable your gradient checking code before training your classifier.if you run numerical gradient computation on every iteration of gradient descent(or in the inner loop of costFunction(…))your code will be very slow.



##### Random initialization: Symmetry breaking

Initialize each $\theta_{ij}^{(l)}$ to a random value in $[\epsilon,\epsilon](i.e.-\epsilon\leq\theta\leq\epsilon)$

E.g. 

Theta1 = rand(10,11)*(2$\times$INIT_EPSILON) - INIT_EPSILON;



random initialization —> implement back-propagation —> gradient checking —> gradient descent  (minimize J)



#### Put it together

##### Training a neural network

Pick a network architecture (connectivity pattern between neurous)

No.of input units: Dimension of features $x^{(i)}$

No.output units: Number of classes

Reasonable default: 1hidden layer,or if>1 hidden llayer,have same no.of hidden units in every layer (usually the more the better)



1. Randomly initialize weights
2. Implement forward propagation to get $h_\theta(x^{(i)})$ for any $x^{(i)}$
3. Implement code to compute cost function $J(\theta)$
4. Implementbackprop to compute partial derivatives $\frac{\partial}{\partial\theta_{jk}^{(l)}}J(\theta)$
5. Use gradient checking to compare $\frac{\partial}{\partial\theta_{jk}^{(l)}}J(\theta)$ computed using backpropagation vs. using numerical estimate gradient of J($ \theta$)
6. Use gradient descent or advanced optimization method with backpropagation to try to minimize $J( \theta)$ as a function of parameters $ \theta$



##### Autonomous driving example



## 10-19（见下一篇）
